version: '3.8'

services:
  # PostgreSQL Database with High Availability
  db:
    image: postgres:15-alpine
    container_name: gsc_db_prod
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-gsc_production}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
      - ./backups:/backups
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - gsc_network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-gsc_production}"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: postgres -c config_file=/etc/postgresql/postgresql.conf

  # Backend API Server with Scaling
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: gsc_api_prod
    restart: always
    environment:
      NODE_ENV: production
      PORT: 3000
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-gsc_production}
      JWT_SECRET: ${JWT_SECRET}
      CORS_ORIGIN: ${CORS_ORIGIN}
      LOG_LEVEL: ${LOG_LEVEL:-warn}
      RATE_LIMIT_WINDOW: ${RATE_LIMIT_WINDOW:-15}
      RATE_LIMIT_MAX: ${RATE_LIMIT_MAX:-50}
      SESSION_SECRET: ${SESSION_SECRET}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      CLUSTER_WORKERS: ${CLUSTER_WORKERS:-2}
      MAX_MEMORY: ${MAX_MEMORY:-1024}
    ports:
      - "${API_PORT:-3000}:3000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - gsc_network
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '0.8'
        reservations:
          memory: 512M
          cpus: '0.3'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Frontend Client with Optimized Nginx
  client:
    build:
      context: .
      dockerfile: Dockerfile.client
      target: production
    container_name: gsc_client_prod
    restart: always
    environment:
      VITE_API_URL: ${VITE_API_URL}
      VITE_APP_NAME: ${VITE_APP_NAME:-GSC Production}
      VITE_ENVIRONMENT: production
      VITE_SENTRY_DSN: ${VITE_SENTRY_DSN}
      VITE_ANALYTICS_ID: ${VITE_ANALYTICS_ID}
    ports:
      - "${CLIENT_PORT:-3001}:80"
    depends_on:
      - api
    networks:
      - gsc_network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.3'
        reservations:
          memory: 128M
          cpus: '0.1'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for Caching and Sessions
  redis:
    image: redis:7-alpine
    container_name: gsc_redis_prod
    restart: always
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD} --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data_prod:/data
      - ./redis/redis.conf:/etc/redis/redis.conf:ro
    networks:
      - gsc_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.2'
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Nginx Load Balancer with SSL
  nginx:
    image: nginx:alpine
    container_name: gsc_nginx_prod
    restart: always
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./nginx/production.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      - api
      - client
    networks:
      - gsc_network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.2'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring and Logging
  promtail:
    image: grafana/promtail:2.9.0
    container_name: gsc_promtail_prod
    restart: always
    volumes:
      - ./logs:/var/log:ro
      - ./monitoring/promtail.yml:/etc/promtail/config.yml:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - gsc_network
    depends_on:
      - api
      - nginx

  # Database Backup Service
  db-backup:
    image: postgres:15-alpine
    container_name: gsc_backup_prod
    restart: 'no'
    environment:
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    networks:
      - gsc_network
    depends_on:
      - db
    command: sh -c "chmod +x /backup.sh && /backup.sh"
    profiles:
      - backup

volumes:
  postgres_data_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/postgres
  redis_data_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/redis

networks:
  gsc_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16